{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Your First Intelligent Agent Team: A Research Asisstant Tool for Curing Diabetes with ADK\n",
    "\n",
    "https://google.github.io/adk-docs/get-started/quickstart/\n",
    "\n",
    "https://google.github.io/adk-docs/tutorials/agent-team/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Environment & Install ADK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-adk in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: anyio>=4.9.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (4.9.0)\n",
      "Requirement already satisfied: authlib>=1.5.1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (1.6.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (8.2.1)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (0.115.13)\n",
      "Requirement already satisfied: google-api-python-client>=2.157.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (2.173.0)\n",
      "Requirement already satisfied: google-cloud-aiplatform>=1.95.1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.98.0)\n",
      "Requirement already satisfied: google-cloud-secret-manager>=2.22.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (2.24.0)\n",
      "Requirement already satisfied: google-cloud-speech>=2.30.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (2.33.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.18.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (2.19.0)\n",
      "Requirement already satisfied: google-genai>=1.17.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (1.20.0)\n",
      "Requirement already satisfied: graphviz>=0.20.2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (0.21)\n",
      "Requirement already satisfied: mcp>=1.8.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (1.9.4)\n",
      "Requirement already satisfied: opentelemetry-api>=1.31.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-gcp-trace>=1.9.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (1.9.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.31.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (1.34.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (2.11.5)\n",
      "Requirement already satisfied: python-dateutil>=2.9.0.post0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (1.0.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.32.4 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (2.32.4)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (2.0.41)\n",
      "Requirement already satisfied: starlette>=0.46.2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (0.46.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (4.12.2)\n",
      "Requirement already satisfied: tzlocal>=5.3 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (5.3.1)\n",
      "Requirement already satisfied: uvicorn>=0.34.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (0.34.3)\n",
      "Requirement already satisfied: websockets>=15.0.1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-adk) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from anyio>=4.9.0->google-adk) (3.8)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from anyio>=4.9.0->google-adk) (1.3.1)\n",
      "Requirement already satisfied: cryptography in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from authlib>=1.5.1->google-adk) (43.0.3)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-api-python-client>=2.157.0->google-adk) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-api-python-client>=2.157.0->google-adk) (2.34.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-api-python-client>=2.157.0->google-adk) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-api-python-client>=2.157.0->google-adk) (2.19.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-api-python-client>=2.157.0->google-adk) (4.1.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (4.25.5)\n",
      "Requirement already satisfied: packaging>=14.3 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (25.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (3.26.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.13.0)\n",
      "Requirement already satisfied: shapely<3.0.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (2.0.6)\n",
      "Requirement already satisfied: docstring_parser<1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (0.16)\n",
      "Requirement already satisfied: cloudpickle<4.0,>=3.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (3.1.1)\n",
      "Requirement already satisfied: google-cloud-trace<2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.16.2)\n",
      "Requirement already satisfied: google-cloud-logging<4 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (3.12.1)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-secret-manager>=2.22.0->google-adk) (0.14.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-storage<3.0.0,>=2.18.0->google-adk) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-storage<3.0.0,>=2.18.0->google-adk) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-storage<3.0.0,>=2.18.0->google-adk) (1.6.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-genai>=1.17.0->google-adk) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from mcp>=1.8.0->google-adk) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from mcp>=1.8.0->google-adk) (2.9.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from mcp>=1.8.0->google-adk) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from mcp>=1.8.0->google-adk) (2.3.6)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from opentelemetry-api>=1.31.0->google-adk) (6.11.0)\n",
      "Requirement already satisfied: opentelemetry-resourcedetector-gcp==1.*,>=1.5.0dev0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from opentelemetry-exporter-gcp-trace>=1.9.0->google-adk) (1.9.0a0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from opentelemetry-sdk>=1.31.0->google-adk) (0.55b1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0->google-adk) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from python-dateutil>=2.9.0.post0->google-adk) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests>=2.32.4->google-adk) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests>=2.32.4->google-adk) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests>=2.32.4->google-adk) (2024.8.30)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from uvicorn>=0.34.0->google-adk) (0.14.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=2.157.0->google-adk) (1.65.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.66.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.157.0->google-adk) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.157.0->google-adk) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.157.0->google-adk) (4.9)\n",
      "Requirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.6.2)\n",
      "Requirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (0.3.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=2.157.0->google-adk) (3.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai>=1.17.0->google-adk) (1.0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.31.0->google-adk) (3.21.0)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from shapely<3.0.0->google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.26.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from cryptography->authlib>=1.5.1->google-adk) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from cffi>=1.12->cryptography->authlib>=1.5.1->google-adk) (2.22)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/tubakaraca/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.157.0->google-adk) (0.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google-adk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# @title Import necessary libraries\n",
    "import os\n",
    "import asyncio\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.agents import LlmAgent\n",
    "#from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure API Keys (Replace with your actual keys!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()  # This loads variables from .env into the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment configured.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "\n",
    "# More supported models can be referenced here: https://ai.google.dev/gemini-api/docs/models#model-variations\n",
    "MODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash\"\n",
    "\n",
    "print(\"\\nEnvironment configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add the root directory of your project to Python path\n",
    "project_root = os.path.abspath(\"../backend\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_credentials = os.getenv(\"PATH_TO_CREDENTIALS\")\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = path_to_credentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the MongoDB collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MongoDB connection established.\n"
     ]
    }
   ],
   "source": [
    "from db.mongodb_client import mongodb_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of the MongoDB database, collection and vector search index\n",
    "DB_NAME = \"diabetes_data\"\n",
    "COLLECTION_NAME = \"records_embeddings\"\n",
    "VS_INDEX_NAME = \"csv_vector_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mongodb_client[DB_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MongoDB collection\n",
    "collection = mongodb_client[DB_NAME][COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client: MongoClient(host=['ac-t38w2lp-shard-00-02.q4fmjuw.mongodb.net:27017', 'ac-t38w2lp-shard-00-01.q4fmjuw.mongodb.net:27017', 'ac-t38w2lp-shard-00-00.q4fmjuw.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, retrywrites=True, w='majority', appname='Search4Cure.diabetes', authsource='admin', replicaset='atlas-lunm1g-shard-0', tls=True, server_api=<pymongo.server_api.ServerApi object at 0x316210650>)\n",
      "Databases: ['diabetes_data', 'admin', 'local']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Client:\", mongodb_client)\n",
    "print(\"Databases:\", mongodb_client.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.operations import SearchIndexModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = os.getenv(\"MONGO_DB\")\n",
    "ATLAS_VECTOR_SEARCH_INDEX = \"csv_vector_index\"\n",
    "CSV_COLLECTION= \"records_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_mongodb.retrievers import MongoDBAtlasHybridSearchRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db.mongodb_client import MONGODB_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=MODEL_GEMINI_2_0_FLASH,\n",
    "    task_type=\"RETRIEVAL_DOCUMENT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_EMBEDDING_MODEL = \"models/embedding-001\"#\"models/gemini-embedding-exp-03-07\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=GEMINI_EMBEDDING_MODEL,\n",
    "    task_type=\"RETRIEVAL_DOCUMENT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_csv_files = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "    connection_string=MONGODB_URI,\n",
    "    namespace=DB_NAME + \".\" + CSV_COLLECTION,\n",
    "    embedding=embedding_model,\n",
    "    index_name=ATLAS_VECTOR_SEARCH_INDEX,\n",
    "    text_key=\"combined_info\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Agent Team \n",
    "\n",
    "In Steps 1 and 2, we built and experimented with a single agent focused solely on weather lookups. While effective for its specific task, real-world applications often involve handling a wider variety of user interactions. We *could* keep adding more tools and complex instructions to our single weather agent, but this can quickly become unmanageable and less efficient.\n",
    "\n",
    "A more robust approach is to build an **Agent Team**. This involves:\n",
    "\n",
    "1. Creating multiple, **specialized agents**, each designed for a specific capability (e.g., one for weather, one for greetings, one for calculations).  \n",
    "2. Designating a **root agent** (or orchestrator) that receives the initial user request.  \n",
    "3. Enabling the root agent to **delegate** the request to the most appropriate specialized sub-agent based on the user's intent.\n",
    "\n",
    "**Why build an Agent Team?**\n",
    "\n",
    "* **Modularity:** Easier to develop, test, and maintain individual agents.  \n",
    "* **Specialization:** Each agent can be fine-tuned (instructions, model choice) for its specific task.  \n",
    "* **Scalability:** Simpler to add new capabilities by adding new agents.  \n",
    "* **Efficiency:** Allows using potentially simpler/cheaper models for simpler tasks (like greetings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**1\\. Define Tools for Sub-Agents**\n",
    "\n",
    "First, let's create the simple Python functions that will serve as tools for our new specialist agents. Remember, clear docstrings are vital for the agents that will use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for CSV Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_files_vector_search_tool(query: str, k: int = 5):\n",
    "    \"\"\"\n",
    "    Perform a vector similarity search on safety procedures.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "        k (int, optional): Number of top results to return. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples (Document, score), where Document is a record\n",
    "              and score is the similarity score (lower is more similar).\n",
    "\n",
    "    Note:\n",
    "        Uses the global vector_store_csv_files for the search.\n",
    "    \"\"\"\n",
    "\n",
    "    vector_search_results = vector_store_csv_files.similarity_search_with_score(\n",
    "        query=query, k=k\n",
    "    )\n",
    "    return vector_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search_tool(query: str):\n",
    "    \"\"\"\n",
    "    Perform a hybrid (vector + full-text) search on safety procedures.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "\n",
    "    Returns:\n",
    "        list: Relevant safety procedure documents from hybrid search.\n",
    "\n",
    "    Note:\n",
    "        Uses both vector_store_csv_files and record_text_search_index.\n",
    "    \"\"\"\n",
    "\n",
    "    hybrid_search = MongoDBAtlasHybridSearchRetriever(\n",
    "        vectorstore=vector_store_csv_files,\n",
    "        search_index_name=\"record_text_search_index\",\n",
    "        top_k=5,\n",
    "    )\n",
    "\n",
    "    hybrid_search_result = hybrid_search.get_relevant_documents(query)\n",
    "\n",
    "    return hybrid_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Optional, List\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "\n",
    "## Generalized Record Document Creator\n",
    "class GenericRecord(BaseModel):\n",
    "    # Flexible for any CSV columns\n",
    "    data: Dict[str, Any]\n",
    "    combined_info: Optional[str] = None\n",
    "    embedding: Optional[List[float]] = None\n",
    "    dataset_id: Optional[str] = None\n",
    "    created_at: datetime = Field(default_factory=datetime.now)\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "## Function to Create the Document\n",
    "def create_generic_record_document(row: Dict[str, Any], dataset_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Create a standardized document for any CSV record with flexible columns.\n",
    "\n",
    "    Args:\n",
    "        row (Dict[str, Any]): The actual CSV row as a dictionary.\n",
    "        dataset_id (str): Reference to the parent dataset document.\n",
    "\n",
    "    Returns:\n",
    "        dict: Cleaned and standardized MongoDB document.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean keys: remove leading/trailing whitespace, lowercase, etc. (optional)\n",
    "        cleaned_row = {k.strip(): v for k, v in row.items()}\n",
    "\n",
    "        # Create combined_info string for text search\n",
    "        combined_info = \" \".join(f\"{k}: {v}\" for k, v in cleaned_row.items())\n",
    "\n",
    "        # Package into a generic Pydantic record\n",
    "        record = GenericRecord(\n",
    "            data=cleaned_row,\n",
    "            combined_info=combined_info,\n",
    "            dataset_id=dataset_id\n",
    "        )\n",
    "\n",
    "        return record.dict()\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Invalid record data: {e!s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool to add new record\n",
    "def create_new_record(new_record: Dict[str, any]) -> dict:\n",
    "    \"\"\"\n",
    "    Create and validate a new generic CSV record.\n",
    "\n",
    "    Args:\n",
    "        new_record (dict): Dictionary containing a row from a CSV file. \n",
    "                           Must include 'dataset_id' as a key.\n",
    "\n",
    "    Returns:\n",
    "        dict: Validated and formatted record document.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input data is invalid or incomplete.\n",
    "\n",
    "    Note:\n",
    "        Uses Pydantic for data validation via create_generic_record_document function.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataset_id = new_record.pop(\"dataset_id\", None)\n",
    "        if not dataset_id:\n",
    "            raise ValueError(\"Missing required field 'dataset_id' in the new record.\")\n",
    "\n",
    "        document = create_generic_record_document(new_record, dataset_id)\n",
    "        return document\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error creating new record: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_embeddings_collection_tools = [\n",
    "    csv_files_vector_search_tool,\n",
    "    #hybrid_search_tool,\n",
    "    create_new_record,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for Article Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from retriever.rag_retriever import vector_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"diabetes_data\"\n",
    "COLLECTION_NAME = \"docs_multimodal\"\n",
    "VS_INDEX_NAME = \"multimodal_vector_index\"\n",
    "# Connect to the MongoDB collection\n",
    "collection = mongodb_client[DB_NAME][COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_page_vector_search_tool(\n",
    "    query: str,\n",
    "    model: str = \"sbert\",\n",
    "    collection_name: str = COLLECTION_NAME,\n",
    "    )-> str:\n",
    "    \"\"\"\n",
    "    Search academic papers (page-level) using a text query via multimodal embeddings.\n",
    "    Returns the top 5 page-level summaries with citations.\n",
    "\n",
    "    Args:\n",
    "        query (str): The textual search query.\n",
    "        model (str): Embedding model (\"sbert\", \"clip\", \"voyage\").\n",
    "        collection (str): MongoDB collection name to search in.\n",
    "\n",
    "    Returns:\n",
    "        str: Top 5 matching pages, each with citation and summary.\n",
    "        \n",
    "    \"\"\"\n",
    "    collection_ref = mongodb_client[DB_NAME][collection_name]\n",
    "    results = vector_search(query, model=model, collection=collection_ref, display_images=False)\n",
    "    if not results:\n",
    "        return \"No relevant pages found.\"\n",
    "    \n",
    "    summaries = []\n",
    "    for r in results[:5]:\n",
    "        title = r.get(\"pdf_title\", \"Unknown Title\")\n",
    "        page = r.get(\"page_number\", \"?\")\n",
    "        text = r.get(\"summary\") or r.get(\"page_text\", \"\")[:300]\n",
    "        summaries.append(f\"[{title}, Page {page}]: {text.strip()}\")\n",
    "\n",
    "    return \"\\n\\n\".join(summaries)  # return top 5 summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\") #gemini-pro-vision\n",
    "\n",
    "def extract_info_from_page_image(image: Image.Image, pdf_title: str, page_number: int) -> str:\n",
    "    \"\"\"\n",
    "    Use Gemini to extract citations, figures/tables, and a summary from a page image.\n",
    "    \"\"\"\n",
    "    #response = requests.get(gcs_url)\n",
    "    #image = Image.open(BytesIO(response.content))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are analyzing a scientific paper page image from the PDF titled: \"{pdf_title}\", page {page_number}.\n",
    "    Please extract the following:\n",
    "    1. All citations on the page (e.g., [1], Smith et al. 2020).\n",
    "    2. Any tables or figures, including titles or captions.\n",
    "    3. A brief summary of the page content.\n",
    "    \n",
    "    Return output in markdown with the following format:\n",
    "    **Citations:** ...\n",
    "    **Figures/Tables:** ...\n",
    "    **Summary:** ...\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content([prompt, image])\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Gemini processing error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_PROJECT = os.getenv(\"GCS_PROJECT\")\n",
    "GCS_BUCKET = os.getenv(\"GCS_BUCKET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the GCS client and bucket\n",
    "gcs_client = storage.Client(project=GCS_PROJECT)\n",
    "gcs_bucket = gcs_client.bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from google.cloud import storage\n",
    "\n",
    "def get_image_from_gcs(gcs_bucket, key: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Download image bytes from GCS.\n",
    "\n",
    "    Args:\n",
    "        gcs_bucket: GCS bucket instance.\n",
    "        key (str): Blob key in the bucket.\n",
    "\n",
    "    Returns:\n",
    "        bytes: Image bytes.\n",
    "    \"\"\"\n",
    "    blob = gcs_bucket.blob(key)\n",
    "    return blob.download_as_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "from langchain.agents import tool\n",
    "#from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def vector_search_image_tool(\n",
    "    collection_name: str,\n",
    "    image_bytes: Optional[bytes] = None,\n",
    "    text_query: Optional[str] = None,  \n",
    "    ) -> str:\n",
    "    \"\"\"\n",
    "    Search academic papers using either an image or text query. If text is provided, it generates\n",
    "    a CLIP embedding from the query and searches against page images. If image is provided, it\n",
    "    searches using image embeddings.\n",
    "\n",
    "    Args:\n",
    "        image_bytes (bytes, optional): Query image content.\n",
    "        text_query (str, optional): Text query to generate image embedding.\n",
    "        collection_name (str): MongoDB collection name.\n",
    "\n",
    "    Returns:\n",
    "        str: Top 5 matching pages with citation and Gemini summary.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    collection_ref = db[collection_name]\n",
    "\n",
    "    # Determine search mode\n",
    "    if image_bytes:\n",
    "        try:\n",
    "            query_image = Image.open(BytesIO(image_bytes))\n",
    "        except Exception as e:\n",
    "            return f\"Invalid image input: {e}\"\n",
    "        results = vector_search(query_image, model=\"clip_image\", collection=collection_ref, display_images=False)\n",
    "\n",
    "    elif text_query:\n",
    "        results = vector_search(text_query, model=\"clip\", collection=collection_ref, display_images=False)\n",
    "\n",
    "    else:\n",
    "        return \"Either image_bytes or text_query must be provided.\"\n",
    "    \n",
    "    if not results:\n",
    "        return \"No matching results found.\"\n",
    "        \n",
    "    output = []\n",
    "    for r in results[:5]:\n",
    "        pdf_title = r.get(\"pdf_title\", \"Unknown Title\")\n",
    "        page_number = r.get(\"page_number\", -1)\n",
    "        gcs_key = r.get(\"gcs_key\", \"\")\n",
    "        doc_id = r.get(\"_id\")  # Ensure this is present in your search result\n",
    "\n",
    "        # Check for existing gemini_summary in DB\n",
    "        cached_doc = collection_ref.find_one({\"_id\": doc_id}, {\"gemini_summary\": 1})\n",
    "        if cached_doc and cached_doc.get(\"gemini_summary\"):\n",
    "            summary = cached_doc[\"gemini_summary\"]\n",
    "        else:\n",
    "            # If not cached, fetch image + generate Gemini summary\n",
    "            try:\n",
    "                page_bytes = get_image_from_gcs(gcs_bucket, gcs_key)\n",
    "                page_image = Image.open(BytesIO(page_bytes))\n",
    "            except Exception as e:\n",
    "                return f\"Failed to fetch page image: {e}\"\n",
    "            else:\n",
    "                summary = extract_info_from_page_image(page_image, pdf_title, page_number)\n",
    "\n",
    "                # Save summary to DB\n",
    "                collection_ref.update_one(\n",
    "                    {\"_id\": doc_id},\n",
    "                    {\"$set\": {\"gemini_summary\": summary}},\n",
    "                )\n",
    "\n",
    "        citation = f\"### {pdf_title}, Page {page_number}\"\n",
    "        output.append(f\"{citation}\\n{summary.strip()}\")\n",
    "        \n",
    "    return \"\\n\\n\".join(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_multimodal_collection_tools = [article_page_vector_search_tool, vector_search_image_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_purpose = \"\"\"\n",
    "You are an intelligent Multimodal Dataset and Document Assistant Agent. You help users interact with structured CSV datasets and unstructured academic articles, especially those in PDF format. These data sources are pre-indexed with vector embeddings and metadata, allowing efficient search and retrieval across both tabular and visual/textual domains.\n",
    "Unless specified use all datasets to find the results. \n",
    "Your key responsibilities include:\n",
    "\n",
    "Use csv_files_vector_search_agent and create_new_record_agent for CSV related queries.\n",
    "Use article_page_vector_search_agent and vector_search_image_agent for PDF data extraction. \n",
    "\n",
    "1. csv_files_vector_search_agent: Searching and retrieving from CSV datasets:\n",
    "  - Use search and similarity tools to find relevant rows based on natural language queries.\n",
    "  - Retrieve records with the highest hybrid or semantic similarity scores.\n",
    "  - Present relevant CSV content clearly, along with metadata such as column names and file name.\n",
    "\n",
    "2. create_new_record_agent: Creating new CSV records:\n",
    "  - When provided with a dictionary representing a row, use the `create_new_record` tool to validate and structure it.\n",
    "  - Ensure the new record includes a `dataset_id` and other available fields.\n",
    "  - Construct a `combined_info` string to support downstream embedding and search.\n",
    "\n",
    "3. article_page_vector_search_agent: Handling academic PDF articles:\n",
    "  - Use `article_page_vector_search_tool` to retrieve relevant page-level summaries from academic PDFs using a query.\n",
    "  \n",
    "\n",
    "\n",
    "4. csv_files_vector_search_agent: Interpreting and comparing records:\n",
    "  - Explain the meaning of individual records or fields, in both CSV and PDF contexts.\n",
    "  - Detect patterns across results, such as common entities, table structures, or outliers.\n",
    "  - Help users compare information from CSV datasets and PDF documents when relevant.\n",
    "\n",
    "5. csv_files_vector_search_agent: Dataset/document context awareness:\n",
    "  - Understand that CSVs have varying schemas; don't assume fixed columns.\n",
    "  - Use metadata like `file_name`, `n_columns`, `n_rows`, or `pdf_title`, `page_number`, `gcs_key`, and `url` to ground your responses.\n",
    "  - Avoid making assumptions about missing content—only respond using indexed or retrieved information.\n",
    "\n",
    "6. Embedding-based insights:\n",
    "  - When applicable, use similarity scores or semantic reasoning to explain result relevance.\n",
    "  - Explain whether a page/image was returned due to textual match, visual similarity, or both.\n",
    "\n",
    "7. vector_search_image_agent:\n",
    "    - Use `vector_search_image_tool` to perform image-based search on PDF pages using CLIP embeddings.\n",
    "    - Present results with clear summaries, proper citations (including PDF title and page number), and structured insight from both page text and image content.\n",
    "\n",
    "8. Providing structured output:\n",
    "  For CSV:\n",
    "    CSV Record Summary:\n",
    "    - Dataset: [file_name] (ID: [dataset_id])\n",
    "    - Columns: [col1, col2, ...]\n",
    "    - Record:\n",
    "        col1: value1\n",
    "        col2: value2\n",
    "        ...\n",
    "    - Notes: [Any patterns, anomalies, or insights]\n",
    "\n",
    "  For PDF:\n",
    "    Article Page Match:\n",
    "    - Title: [pdf_title]\n",
    "    - Page: [page_number]\n",
    "    - Summary: [Gemini or page_text extract]\n",
    "    - Notes: [Mention if image, table, or citation was detected]\n",
    "\n",
    "8. Acting responsibly:\n",
    "  - DO NOT make up any values.\n",
    "  - Clearly state when a record, page, or result is not found.\n",
    "  - Always cite retrieved content from PDFs with accurate source info (title, page).\n",
    "  - Respect dataset diversity and content type (CSV vs. image vs. article page).\n",
    "\n",
    "This assistant supports analysts, researchers, and non-technical users in exploring multimodal data and extracting reliable insights from both structured CSVs and academic PDFs, using state-of-the-art embeddings and Gemini-based summarization.\n",
    "\n",
    "DO NOT MAKE UP ANY INFORMATION.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**2\\. Define the Sub-Agents **\n",
    "\n",
    "Now, create the `Agent` instances for our specialists. Notice their highly focused `instruction` and, critically, their clear `description`. The `description` is the primary information the *root agent* uses to decide *when* to delegate to these sub-agents.\n",
    "\n",
    "**Best Practice:** Sub-agent `description` fields should accurately and concisely summarize their specific capability. This is crucial for effective automatic delegation.\n",
    "\n",
    "**Best Practice:** Sub-agent `instruction` fields should be tailored to their limited scope, telling them exactly what to do and *what not* to do (e.g., \"Your *only* task is...\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_MODEL = MODEL_GEMINI_2_0_FLASH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'csv_files_vector_search_agent' created using model 'gemini-2.0-flash'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the agent\n",
    "csv_files_vector_search_agent = Agent(\n",
    "    name=\"csv_files_vector_search_agent\",\n",
    "    model=AGENT_MODEL,\n",
    "    description=\"Performs a vector similarity search on safety procedures from CSV files.\",\n",
    "    instruction=\"You are an agent that performs a semantic similarity search on patient data about diabetes\"\n",
    "                \"stored in CSV files using the 'csv_files_vector_search_tool'. \"\n",
    "                \"Return the most relevant entries from the database based on the user's query.\",\n",
    "    tools=[csv_files_vector_search_tool],\n",
    ")\n",
    "\n",
    "print(f\"Agent '{csv_files_vector_search_agent.name}' created using model '{AGENT_MODEL}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_search_agent = Agent(\n",
    "    name=\"hybrid_search_agent\",\n",
    "    model=AGENT_MODEL,\n",
    "    description=\"Performs a hybrid (vector + full-text) search on CSV safety records.\",\n",
    "    instruction=\"You are an agent that retrieves the most relevant CSV records related to safety using both full-text and vector similarity search. Use the 'hybrid_search_tool'.\",\n",
    "    tools=[hybrid_search_tool],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_record_agent = Agent(\n",
    "    name=\"create_record_agent\",\n",
    "    model=AGENT_MODEL,\n",
    "    description=\"Creates and validates new records for a CSV dataset.\",\n",
    "    instruction=\"You are a data creation agent. When a user submits a new CSV row with a dataset ID, validate and format it using the 'create_new_record' tool.\",\n",
    "    tools=[create_new_record],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_page_search_agent = Agent(\n",
    "    name=\"article_page_search_agent\",\n",
    "    model=AGENT_MODEL,\n",
    "    description=\"Search academic papers (page-level) using a text query via multimodal embeddings.Returns the top 5 page-level summaries with citations.\",\n",
    "    instruction=\"You are an academic search agent. Use the 'article_page_vector_search_tool' to find relevant page-level results from academic papers. \",\n",
    "    tools=[article_page_vector_search_tool],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search_image_agent = Agent(\n",
    "    name=\"vector_search_image_agent\",\n",
    "    model=AGENT_MODEL,\n",
    "    description=\"Search academic papers using either an image or text query. If text is provided, it generates a CLIP embedding from the query and searches against page images. If image is provided, it searches using image embeddings.\",\n",
    "    instruction=\"You are a multimodal search agent. If the user provides an image or a descriptive text, use 'vector_search_image_tool' to return the top 5 academic page results with citations and summaries.\",\n",
    "    tools=[vector_search_image_tool],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import LlmAgent, BaseAgent\n",
    "from google.adk.tools import agent_tool\n",
    "from pydantic import BaseModel\n",
    "#from google.adk import types\n",
    "from google.adk.events import Event\n",
    "\n",
    "class ImageGeneratorAgent(BaseAgent):\n",
    "    name: str = \"ImageGen\"\n",
    "    description: str = \"Generates an image based on a prompt.\"\n",
    "\n",
    "    async def _run_async_impl(self, ctx):\n",
    "        prompt = ctx.session.state.get(\"image_prompt\", \"default prompt\")\n",
    "        image_bytes = b\"...\"  # replace with actual logic\n",
    "        yield Event(\n",
    "            author=self.name,\n",
    "            content=types.Content(parts=[types.Part.from_bytes(image_bytes, \"image/png\")])\n",
    "        )\n",
    "\n",
    "# Wrap the custom agent as a tool\n",
    "image_tool = agent_tool.AgentTool(agent=ImageGeneratorAgent())\n",
    "\n",
    "# Use the tool in an LlmAgent\n",
    "artist_agent = LlmAgent(\n",
    "    name=\"Artist\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"Create a prompt and use the ImageGen tool to generate the image.\",\n",
    "    tools=[image_tool]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**3\\. Define the Root Agent (Medical Research Agent for Diabetes v2) with Sub-Agents**\n",
    "\n",
    "Now, we upgrade our `search_agent`. The key changes are:\n",
    "\n",
    "* Adding the `sub_agents` parameter: We pass a list containing the `_agent` and `_agent` instances we just created.  \n",
    "* Updating the `instruction`: We explicitly tell the root agent *about* its sub-agents and *when* it should delegate tasks to them.\n",
    "\n",
    "**Key Concept: Automatic Delegation (Auto Flow)** By providing the `sub_agents` list, ADK enables automatic delegation. When the root agent receives a user query, its LLM considers not only its own instructions and tools but also the `description` of each sub-agent. If the LLM determines that a query aligns better with a sub-agent's described capability (e.g., \"Handles simple greetings\"), it will automatically generate a special internal action to *transfer control* to that sub-agent for that turn. The sub-agent then processes the query using its own model, instructions, and tools.\n",
    "\n",
    "**Best Practice:** Ensure the root agent's instructions clearly guide its delegation decisions. Mention the sub-agents by name and describe the conditions under which delegation should occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import agent_tool\n",
    "\n",
    "# Define the purpose/instruction of the coordinator agent\n",
    "COORDINATOR_PURPOSE = agent_purpose\n",
    "\"\"\"\n",
    "You are the coordinator agent of the search4cure.AI Diabetes Research Assistant System.\n",
    "\n",
    "You orchestrate a team of specialized sub-agents and tools that interact with structured CSV datasets and unstructured academic documents (PDFs), both pre-embedded for semantic and visual retrieval. Your role is to:\n",
    "\n",
    "1. Understand the user’s query in context.\n",
    "2. Decide which sub-agent or tool to invoke:\n",
    "    - Use `csv_files_vector_search_agent` for structured tabular data.\n",
    "    - Use `article_page_vector_search_tool` to retrieve semantic matches from academic PDFs, using sbert.\n",
    "    - Use `vector_search_image_tool` to retrieve visually similar content using CLIP.\n",
    "    - Use `create_new_record` to add new structured entries to indexed CSV datasets.\n",
    "    - Use 'artist agent' to generate image based on a query.\n",
    "3. Aggregate results across modalities when necessary.\n",
    "4. Format structured outputs for clarity and citation.\n",
    "\n",
    "You ensure answers are factual, properly cited, and clearly distinguish between text, table, and image-based evidence. Use source metadata like dataset_id, file_name, pdf_title, and page_number to support your response.\n",
    "\n",
    "DO NOT fabricate information. Always cite sources and explain reasoning clearly.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Mid-level agent combining tools\n",
    "research_assistant = LlmAgent(\n",
    "    name=\"research_assistant_for_the_cure_Diabetes\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description= COORDINATOR_PURPOSE,\n",
    "    tools=[agent_tool.AgentTool(agent=csv_files_vector_search_agent), \n",
    "           agent_tool.AgentTool(agent=create_record_agent), \n",
    "           agent_tool.AgentTool(agent=article_page_search_agent), \n",
    "           agent_tool.AgentTool(agent=vector_search_image_agent),\n",
    "           agent_tool.AgentTool(agent=artist_agent)]\n",
    ")\n",
    "\n",
    "# High-level agent delegating research\n",
    "report_writer = LlmAgent(\n",
    "    name=\"ReportWriter\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"Write a report on the given question. Use the ResearchAssistant to gather information.\",\n",
    "    tools=[agent_tool.AgentTool(agent=research_assistant)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**4\\. Interact with the Agent**\n",
    "\n",
    "We need a way to send messages to our agent and receive its responses. Since LLM calls and tool executions can take time, ADK's `Runner` operates asynchronously.\n",
    "\n",
    "We'll define an `async` helper function (`call_agent_async`) that:\n",
    "\n",
    "1. Takes a user query string.  \n",
    "2. Packages it into the ADK `Content` format.  \n",
    "3. Calls `runner.run_async`, providing the user/session context and the new message.  \n",
    "4. Iterates through the **Events** yielded by the runner. Events represent steps in the agent's execution (e.g., tool call requested, tool result received, intermediate LLM thought, final response).  \n",
    "5. Identifies and prints the **final response** event using `event.is_final_response()`.\n",
    "\n",
    "**Why `async`?** Interactions with LLMs and potentially tools (like external APIs) are I/O-bound operations. Using `asyncio` allows the program to handle these operations efficiently without blocking execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Agent Interaction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define Agent Interaction Function\n",
    "\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "async def call_agent_async(query: str, runner, user_id, session_id):\n",
    "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
    "  print(f\"\\n>>> User Query: {query}\")\n",
    "\n",
    "  # Prepare the user's message in ADK format\n",
    "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "\n",
    "  final_response_text = \"Agent did not produce a final response.\" # Default\n",
    "\n",
    "  # Key Concept: run_async executes the agent logic and yields Events.\n",
    "  # We iterate through events to find the final answer.\n",
    "  async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "      # You can uncomment the line below to see *all* events during execution\n",
    "      print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "      # Key Concept: is_final_response() marks the concluding message for the turn.\n",
    "      if event.is_final_response():\n",
    "          if event.content and event.content.parts:\n",
    "             # Assuming text response in the first part\n",
    "             final_response_text = event.content.parts[0].text\n",
    "          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "             final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "          # Add more checks here if needed (e.g., specific error codes)\n",
    "          break # Stop processing events once the final response is found\n",
    "\n",
    "  print(f\"<<< Agent Response: {final_response_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**3\\. Setup Runner and Session Service**\n",
    "\n",
    "To manage conversations and execute the agent, we need two more components:\n",
    "\n",
    "* `SessionService`: Responsible for managing conversation history and state for different users and sessions. The `InMemorySessionService` is a simple implementation that stores everything in memory, suitable for testing and simple applications. It keeps track of the messages exchanged. We'll explore state persistence more in Step 4\\.  \n",
    "* `Runner`: The engine that orchestrates the interaction flow. It takes user input, routes it to the appropriate agent, manages calls to the LLM and tools based on the agent's logic, handles session updates via the `SessionService`, and yields events representing the progress of the interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**4\\. Interact with the Agent Team**\n",
    "\n",
    "Now that we've defined our root agent (`weather_agent_team` - *Note: Ensure this variable name matches the one defined in the previous code block, likely `# @title Define the Root Agent with Sub-Agents`, which might have named it `root_agent`*) with its specialized sub-agents, let's test the delegation mechanism.\n",
    "\n",
    "The following code block will:\n",
    "\n",
    "1.  Define an `async` function `run_team_conversation`.\n",
    "2.  Inside this function, create a *new, dedicated* `InMemorySessionService` and a specific session (`session_001_agent_team`) just for this test run. This isolates the conversation history for testing the team dynamics.\n",
    "3.  Create a `Runner` (`runner_agent_team`) configured to use our `weather_agent_team` (the root agent) and the dedicated session service.\n",
    "4.  Use our updated `call_agent_async` function to send different types of queries (greeting, weather request, farewell) to the `runner_agent_team`. We explicitly pass the runner, user ID, and session ID for this specific test.\n",
    "5.  Immediately execute the `run_team_conversation` function.\n",
    "\n",
    "We expect the following flow:\n",
    "\n",
    "1.  The \"Hello there!\" query goes to `runner_agent_team`.\n",
    "2.  The root agent (`weather_agent_team`) receives it and, based on its instructions and the `greeting_agent`'s description, delegates the task.\n",
    "3.  `greeting_agent` handles the query, calls its `say_hello` tool, and generates the response.\n",
    "4.  The \"What is the weather in New York?\" query is *not* delegated and is handled directly by the root agent using its `get_weather` tool.\n",
    "5.  The \"Thanks, bye!\" query is delegated to the `farewell_agent`, which uses its `say_goodbye` tool.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Attempting notebook-style execution using 'await'...\n",
      "\n",
      "--- Running Search4Cure Diabetes Research Agent Team ---\n",
      "✅ Session initialized: App='search4cure_diabetes_team', User='user_1', Session='session_diabetes_001'\n",
      "✅ Runner created for root agent 'research_assistant_for_the_cure_Diabetes'\n",
      "\n",
      ">>> User Query: Find patients over 65 with high blood pressure from the dataset.\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id='adk-9491a1d7-525e-4e63-a30b-98bb1facddd7', args={'request': 'patients over 65 with high blood pressure'}, name='csv_files_vector_search_agent'), function_response=None, text=None)] role='model'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=FunctionResponse(will_continue=None, scheduling=None, id='adk-9491a1d7-525e-4e63-a30b-98bb1facddd7', name='csv_files_vector_search_agent', response={'result': 'The search results show patients with high blood pressure, with age values of 7 and 8. Since the age metadata is encoded, age 7 likely corresponds to the 65+ age group.\\n'}), text=None)] role='user'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='I found patients with high blood pressure, with age values of 7 and 8. Since the age metadata is encoded, age 7 likely corresponds to the 65+ age group.\\n')] role='model'\n",
      "<<< Agent Response: I found patients with high blood pressure, with age values of 7 and 8. Since the age metadata is encoded, age 7 likely corresponds to the 65+ age group.\n",
      "\n",
      "\n",
      ">>> User Query: Give me the information about the historical improvements on the cure of Diabetes?\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id='adk-da274cb3-1a8a-4506-9260-d18bf3e2ef95', args={'request': 'historical improvements on the cure of Diabetes'}, name='article_page_search_agent'), function_response=None, text=None)] role='model'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=FunctionResponse(will_continue=None, scheduling=None, id='adk-da274cb3-1a8a-4506-9260-d18bf3e2ef95', name='article_page_search_agent', response={'result': 'I was unable to find any relevant pages based on your search query. I can try a different query if you like.\\n'}), text=None)] role='user'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='I am sorry, I could not find any relevant information about the historical improvements on the cure of Diabetes.\\n')] role='model'\n",
      "<<< Agent Response: I am sorry, I could not find any relevant information about the historical improvements on the cure of Diabetes.\n",
      "\n",
      "\n",
      ">>> User Query: Add this row to the diabetes dataset: age: 50, bmi: 29.2, glucose: 130, outcome: 1.\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='Could you please provide the dataset ID for adding the new record?\\n')] role='model'\n",
      "<<< Agent Response: Could you please provide the dataset ID for adding the new record?\n",
      "\n",
      "\n",
      ">>> User Query: What does the glucose column represent in the diabetes file?\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id='adk-6871d60f-49b8-4f95-aea3-ea2b29e8518c', args={'request': 'meaning of glucose column in diabetes dataset'}, name='csv_files_vector_search_agent'), function_response=None, text=None)] role='model'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=FunctionResponse(will_continue=None, scheduling=None, id='adk-6871d60f-49b8-4f95-aea3-ea2b29e8518c', name='csv_files_vector_search_agent', response={'result': 'The glucose column in the diabetes dataset represents the plasma glucose concentration after a 2-hour oral glucose tolerance test. It is a measure of blood sugar levels.\\n'}), text=None)] role='user'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='The glucose column in the diabetes dataset represents the plasma glucose concentration after a 2-hour oral glucose tolerance test, which is a measure of blood sugar levels.\\n')] role='model'\n",
      "<<< Agent Response: The glucose column in the diabetes dataset represents the plasma glucose concentration after a 2-hour oral glucose tolerance test, which is a measure of blood sugar levels.\n",
      "\n",
      "\n",
      ">>> User Query: Is there a correlation between the glucose levels in the CSV and findings in any PDF pages?\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id='adk-382b11e2-f8f7-4488-b430-13e7ac61de36', args={'request': 'correlation between glucose levels and diabetes'}, name='article_page_search_agent'), function_response=None, text=None), Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id='adk-9c28a091-f127-4246-986f-362e2c561efb', args={'request': 'correlation between glucose levels and diabetes'}, name='csv_files_vector_search_agent'), function_response=None, text=None)] role='model'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=FunctionResponse(will_continue=None, scheduling=None, id='adk-382b11e2-f8f7-4488-b430-13e7ac61de36', name='article_page_search_agent', response={'result': 'I\\'m sorry, but I couldn\\'t find any relevant pages in the academic papers database using the query \"correlation between glucose levels and diabetes\". Would you like me to try a different query or model?\\n'}), text=None), Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=FunctionResponse(will_continue=None, scheduling=None, id='adk-9c28a091-f127-4246-986f-362e2c561efb', name='csv_files_vector_search_agent', response={'result': \"The search results show several entries with glucose levels and other diabetes-related factors. Each entry includes 'Glucose' and 'Outcome' (diabetes outcome), along with other variables like 'Age', 'BMI', 'BloodPressure', and 'DiabetesPedigreeFunction'. The data suggests a potential correlation between glucose levels and diabetes, as these factors are recorded for each patient. To determine the exact nature and strength of the correlation, a statistical analysis would be needed.\\n\"}), text=None)] role='user'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"I was unable to find any relevant pages in the academic papers database. However, the CSV dataset includes 'Glucose' and 'Outcome' (diabetes outcome), along with other variables like 'Age', 'BMI', 'BloodPressure', and 'DiabetesPedigreeFunction'. The data suggests a potential correlation between glucose levels and diabetes. To determine the exact nature and strength of the correlation, a statistical analysis would be needed.\\n\")] role='model'\n",
      "<<< Agent Response: I was unable to find any relevant pages in the academic papers database. However, the CSV dataset includes 'Glucose' and 'Outcome' (diabetes outcome), along with other variables like 'Age', 'BMI', 'BloodPressure', and 'DiabetesPedigreeFunction'. The data suggests a potential correlation between glucose levels and diabetes. To determine the exact nature and strength of the correlation, a statistical analysis would be needed.\n",
      "\n",
      "\n",
      ">>> User Query: Get me a list of research papers on the topic Machine Learning Methods on the treatment of Diabetes.\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id='adk-ee0a9330-6b8e-43ed-a082-fb9be94a07ae', args={'request': 'Machine Learning Methods on the treatment of Diabetes'}, name='article_page_search_agent'), function_response=None, text=None)] role='model'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=FunctionResponse(will_continue=None, scheduling=None, id='adk-ee0a9330-6b8e-43ed-a082-fb9be94a07ae', name='article_page_search_agent', response={'result': 'I am sorry, I could not find any relevant pages based on your query. I can try a different query or model if you like.\\n'}), text=None)] role='user'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='I am sorry, I could not find any relevant research papers based on your query. I can try a different query if you like.\\n')] role='model'\n",
      "<<< Agent Response: I am sorry, I could not find any relevant research papers based on your query. I can try a different query if you like.\n",
      "\n",
      "\n",
      ">>> User Query: Summarize the first page of the PDF titled 'Early_Stage_Diabetes_Prediction_via_Extreme_Learning_Machine'.\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id='adk-d9980cb8-a7b5-4755-befe-73e5966112f9', args={'request': \"first page of the PDF titled 'Early_Stage_Diabetes_Prediction_via_Extreme_Learning_Machine'\"}, name='article_page_search_agent'), function_response=None, text=None)] role='model'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=FunctionResponse(will_continue=None, scheduling=None, id='adk-d9980cb8-a7b5-4755-befe-73e5966112f9', name='article_page_search_agent', response={'result': \"I'm sorry, I couldn't find any relevant pages based on your query. Can I help you with something else?\\n\"}), text=None)] role='user'\n",
      "  [Event] Author: research_assistant_for_the_cure_Diabetes, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"I am sorry, I could not find the PDF titled 'Early_Stage_Diabetes_Prediction_via_Extreme_Learning_Machine' in the database.\\n\")] role='model'\n",
      "<<< Agent Response: I am sorry, I could not find the PDF titled 'Early_Stage_Diabetes_Prediction_via_Extreme_Learning_Machine' in the database.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Interact with the Search4Cure Diabetes Agent Team\n",
    "import asyncio\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "\n",
    "# Set your root agent name\n",
    "root_agent_var_name = 'research_assistant'  # Updated for your ReportWriter agent\n",
    "\n",
    "# Check if the root agent exists\n",
    "if root_agent_var_name not in globals():\n",
    "    print(f\"⚠️ Root agent '{root_agent_var_name}' not found. Cannot define run_team_conversation.\")\n",
    "    report_writer = None  # Just for safe fallback\n",
    "\n",
    "if root_agent_var_name in globals() and globals()[root_agent_var_name]:\n",
    "    async def run_team_conversation():\n",
    "        print(\"\\n--- Running Search4Cure Diabetes Research Agent Team ---\")\n",
    "\n",
    "        # Initialize in-memory session\n",
    "        session_service = InMemorySessionService()\n",
    "        APP_NAME = \"search4cure_diabetes_team\"\n",
    "        USER_ID = \"user_1\"\n",
    "        SESSION_ID = \"session_diabetes_001\"\n",
    "        session = await session_service.create_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
    "        )\n",
    "        print(f\"✅ Session initialized: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "        actual_root_agent = globals()[root_agent_var_name]\n",
    "\n",
    "        # Initialize runner\n",
    "        runner = Runner(\n",
    "            agent=actual_root_agent,\n",
    "            app_name=APP_NAME,\n",
    "            session_service=session_service\n",
    "        )\n",
    "        print(f\"✅ Runner created for root agent '{actual_root_agent.name}'\")\n",
    "\n",
    "        # --- Test Interactions ---\n",
    "        await call_agent_async(query=\"Find patients over 65 with high blood pressure from the dataset.\",\n",
    "                               runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "\n",
    "        await call_agent_async(query=\"Give me the information about the historical improvements on the cure of Diabetes?\",\n",
    "                               runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "\n",
    "        await call_agent_async(query=\"Add this row to the diabetes dataset: age: 50, bmi: 29.2, glucose: 130, outcome: 1.\",\n",
    "                               runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "\n",
    "        await call_agent_async(query=\"What does the glucose column represent in the diabetes file?\",\n",
    "                               runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "        \n",
    "        await call_agent_async(query=\"Is there a correlation between the glucose levels in the CSV and findings in any PDF pages?\",\n",
    "                               runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "        \n",
    "        await call_agent_async(query=\"Get me a list of research papers on the topic Machine Learning Methods on the treatment of Diabetes.\",\n",
    "                               runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "        \n",
    "        await call_agent_async(query=\"Summarize the first page of the PDF titled 'Early_Stage_Diabetes_Prediction_via_Extreme_Learning_Machine'.\",\n",
    "                               runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "\n",
    "    # Notebook execution\n",
    "    print(\"ℹ️ Attempting notebook-style execution using 'await'...\")\n",
    "    await run_team_conversation()\n",
    "\n",
    "    # For .py script execution (uncomment if needed):\n",
    "    \"\"\"\n",
    "    if __name__ == \"__main__\":\n",
    "        print(\"ℹ️ Running async agent team flow using asyncio.run()...\")\n",
    "        asyncio.run(run_team_conversation())\n",
    "    \"\"\"\n",
    "else:\n",
    "    print(\"⚠️ Skipping execution: root agent not defined correctly.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
